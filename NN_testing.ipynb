{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "niftypath = \"/mnt/c/Users/Patrick/Documents/MPHYS_DATA_NIFTY\"\n",
    "croppath = \"/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_352/1715557382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create data loaders.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-014-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-003-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-018-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-011-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-002-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-015-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-017-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-008-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-007-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-006-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-012-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-005-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-010-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-019-RTSTRUCT.nii\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "transform = ToTensor()\n",
    "\n",
    "class CustomImageDataset():\n",
    "    def __init__(self, croppath, transform=None, target_transfrom=None):\n",
    "        #self.img_labels = pd.read_csv(\"/mnt/c/Users/Patrick/Documents/NSCLC Radiomics Lung1.clinical-version3-Oct 2019(1).csv\")\n",
    "        self.img_labels = pd.read_csv(\"/mnt/c/Users/Patrick/Documents/cancerdata.csv\")\n",
    "        #print(self.img_labels)\n",
    "        self.img_dir = croppath\n",
    "        self.transform=transform\n",
    "        #print(self.transform)\n",
    "        self.target_transform=target_transfrom\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__ (self, idx):\n",
    "        img_path = os.path.join(self.img_dir, f\"{self.img_labels.iloc[idx, 0]}-RTSTRUCT.nii\")\n",
    "        print(img_path)\n",
    "        image = sitk.ReadImage(img_path)\n",
    "        array = sitk.GetArrayFromImage(image)\n",
    "        tensor = torch.from_numpy(array)\n",
    "        time_to_death = self.img_labels.iloc[idx,8]\n",
    "        dead_status = self.img_labels.iloc[idx,9]\n",
    "        if time_to_death < 1.5*365 and dead_status == 1:\n",
    "            label=1\n",
    "        else:\n",
    "            label=0\n",
    "        print(label)\n",
    "        return(label)\n",
    "dataset = CustomImageDataset(croppath, ToTensor(), None)\n",
    "#print(len(dataset))\n",
    "\n",
    "trainset, valset, testset = torch.utils.data.random_split(dataset, [14,3,3])\n",
    "count=0\n",
    "#print(trainset.__getitem__(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-001-CT.nii\n"
     ]
    }
   ],
   "source": [
    "xyz = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "z,x,y = np.argwhere(xyz)\n",
    "ax.scatter(x,y,z,c=z,alpha = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-005-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-008-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-018-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-003-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-012-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-003-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-018-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-010-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-020-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-013-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-001-RTSTRUCT.nii\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "train_features = next(iter(train_dataloader))\n",
    "test_dataloader = DataLoader(testset, batch_size=4, shuffle=True)\n",
    "test_features = next(iter(train_dataloader))\n",
    "val_dataloader = DataLoader(valset, batch_size=4, shuffle=True)\n",
    "val_features = next(iter(val_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-014-RTSTRUCT.nii\n",
      "0\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-005-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-008-RTSTRUCT.nii\n",
      "1\n",
      "/mnt/c/Users/Patrick/Documents/MPHYS_DATA_CROPPED/LUNG1-002-RTSTRUCT.nii\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_352/3075731861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_352/3075731861.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0059,  0.0072,  0.0827,  0.0241, -0.1065,  0.1820, -0.0950,  0.0086,\n",
      "         0.0079,  0.1463, -0.0107,  0.0735, -0.1773, -0.0520, -0.1743,  0.0215,\n",
      "        -0.0589, -0.0503, -0.0424, -0.0243], grad_fn=<AddBackward0>)\n",
      "tensor([0.0000, 0.0072, 0.0827, 0.0241, 0.0000, 0.1820, 0.0000, 0.0086, 0.0079,\n",
      "        0.1463, 0.0000, 0.0735, 0.0000, 0.0000, 0.0000, 0.0215, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "#x = np.array(tensor[0])\n",
    "#x = torch.tensor(x, dtype=torch.float32)\n",
    "#print(x)\n",
    "#print(x.shape)\n",
    "flat_tensor = tensor[0].flatten(start_dim=0, end_dim=-1)\n",
    "\n",
    "layer1 = nn.Linear(in_features=172*172*172, out_features=20)\n",
    "hidden1 = layer1(flat_tensor)\n",
    "print(hidden1)\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(hidden1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "898a5c184a2456bee6a9e0aa8f1ddb9db550ec871c364d22808e3fc0b1a91ec6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
