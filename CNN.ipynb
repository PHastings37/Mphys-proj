{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install SimpleITK\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "JRGP0dFs_3iR",
        "outputId": "86d690c5-5099-4a10-eb41-cb03513b0590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 16 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5BF5Z3hz_lVg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import os\n",
        "from torchvision.io import read_image\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch import reshape\n",
        "import torchvision\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Conv3d\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "ZiD5Uq9UAQXb",
        "outputId": "948b79a3-7e41-4b76-e3d8-ddc9c931efb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/Mphys project"
      ],
      "metadata": {
        "id": "mN70ec46Aces",
        "outputId": "231f4c4f-f4ee-4b68-c71a-19ef988b606d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Mphys project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C6wIv-US_lVm"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "transform = ToTensor()\n",
        "croppath = \"cropped niftys short\"\n",
        "\n",
        "class CustomImageDataset():\n",
        "    def __init__(self, croppath, transform=None, target_transfrom=None):\n",
        "        #self.img_labels = pd.read_csv(\"/mnt/c/Users/Patrick/Documents/NSCLC Radiomics Lung1.clinical-version3-Oct 2019(1).csv\")\n",
        "        #needs new path\n",
        "        self.img_labels = pd.read_csv(\"cancerdata.csv\")\n",
        "        #print(self.img_labels)\n",
        "        self.img_dir = croppath\n",
        "        self.transform=transform\n",
        "        #print(self.transform)\n",
        "        self.target_transform=target_transfrom\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__ (self, idx):\n",
        "        img_path = os.path.join(self.img_dir, f\"{self.img_labels.iloc[idx, 0]}-GTV-1.nii\")\n",
        "        image = sitk.ReadImage(img_path)\n",
        "        array = sitk.GetArrayFromImage(image)\n",
        "        #tensor = torch.from_numpy(array)\n",
        "        time_to_death = self.img_labels.iloc[idx,8]\n",
        "        dead_status = self.img_labels.iloc[idx,9]\n",
        "        if time_to_death < 1.5*365 and dead_status == 1:\n",
        "            label=1\n",
        "        else:\n",
        "            label=0\n",
        "        \n",
        "        return(array, label)\n",
        "dataset = CustomImageDataset(croppath, ToTensor(), None)\n",
        "#print(len(dataset))\n",
        "\n",
        "trainset, valset, testset = torch.utils.data.random_split(dataset, [24,8,8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lhim6vom_lVn"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "train_features = next(iter(train_dataloader))\n",
        "test_dataloader = DataLoader(testset, batch_size=4, shuffle=True)\n",
        "test_features = next(iter(train_dataloader))\n",
        "val_dataloader = DataLoader(valset, batch_size=4, shuffle=True)\n",
        "val_features = next(iter(val_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g2Bfjfny_lVo",
        "outputId": "9fd11f6e-6854-4bf2-b37a-3d131c44171b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Bg5oJWjl_lVp",
        "outputId": "05042e83-e9dd-46c5-93f3-99dacb5f7cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv3d(4, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (5): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv3d(4, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (9): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv3d(4, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (13): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv3d(4, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (17): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "  \n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv3d(1, 4, 3, 1, 1),\n",
        "            nn.BatchNorm3d(4),#normalises batch\n",
        "            ReLU(inplace=True),#applies a ReLu to the neurons\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),#finds max pool of feature map\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(2048, 2)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)#calls the constructor to execute the convolutions, passes the tensor x and gets the \n",
        "        #result of the convolution passed back.\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x\n",
        "\n",
        "model = Net().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ],
      "metadata": {
        "id": "4B0nQHCZBCKa",
        "outputId": "f6c4d1bd-33d6-4b0a-a307-88e994af339a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [4, 4, 264, 264, 264]             112\n",
            "       BatchNorm3d-2      [4, 4, 264, 264, 264]               8\n",
            "              ReLU-3      [4, 4, 264, 264, 264]               0\n",
            "         MaxPool3d-4      [4, 4, 132, 132, 132]               0\n",
            "            Conv3d-5      [4, 4, 132, 132, 132]             436\n",
            "       BatchNorm3d-6      [4, 4, 132, 132, 132]               8\n",
            "              ReLU-7      [4, 4, 132, 132, 132]               0\n",
            "         MaxPool3d-8         [4, 4, 66, 66, 66]               0\n",
            "            Conv3d-9         [4, 4, 66, 66, 66]             436\n",
            "      BatchNorm3d-10         [4, 4, 66, 66, 66]               8\n",
            "             ReLU-11         [4, 4, 66, 66, 66]               0\n",
            "        MaxPool3d-12         [4, 4, 33, 33, 33]               0\n",
            "           Conv3d-13         [4, 4, 33, 33, 33]             436\n",
            "      BatchNorm3d-14         [4, 4, 33, 33, 33]               8\n",
            "             ReLU-15         [4, 4, 33, 33, 33]               0\n",
            "        MaxPool3d-16         [4, 4, 16, 16, 16]               0\n",
            "           Conv3d-17         [4, 4, 16, 16, 16]             436\n",
            "      BatchNorm3d-18         [4, 4, 16, 16, 16]               8\n",
            "             ReLU-19         [4, 4, 16, 16, 16]               0\n",
            "        MaxPool3d-20            [4, 4, 8, 8, 8]               0\n",
            "           Linear-21                     [4, 2]           4,098\n",
            "================================================================\n",
            "Total params: 5,994\n",
            "Trainable params: 5,994\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 8021.21\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 8301.99\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nr5x0eFo_lVq"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class Net2(Module): \n",
        "  def __init__(self):\n",
        "    super(Net2, self).__init__()\n",
        "    self.conv3d1 = Conv3d(1, 4, 1, 1)\n",
        "    self.conv3d2 = Conv3d(4, 16, 1, 1)\n",
        "    self.conv3d3 = Conv3d(16, 64, 1, 1)\n",
        "    self.conv3d4 = Conv3d(64, 256, 1, 1)\n",
        "    self.Lin1 = Linear(524288, 2048)\n",
        "    self.out = Linear(2048,2)\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv3d1(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    x = F.relu(self.conv3d2(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    x = F.relu(self.conv3d3(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    x = F.relu(self.conv3d4(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    # x = F.relu(self.conv3d5(x))\n",
        "    # x = F.max_pool3d(x, 2, 2)\n",
        "    x = F.relu(self.Lin1(x))\n",
        "    x = torch.flatten(x, start_dim = 1)\n",
        "    x = self.out(x)\n",
        "    return(x)\n",
        "model = Net2().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ],
      "metadata": {
        "id": "PUhrhM8qBPpy",
        "outputId": "8976f875-4c23-4e88-d61b-ffa4a78f5093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0b3903dc82c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m264\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m264\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m264\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7b3dbf4bf46b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3d4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3d5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Net2' object has no attribute 'conv3d5'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fE0hMfu_lVr"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, total_loss, epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X = reshape(X, (X.shape[0],1,264,264,264))\n",
        "        X = X.float()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        total_loss += loss\n",
        "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn, total_correct, epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,264,264,264))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            total_correct += correct\n",
        "    test_loss /= num_batches\n",
        "  \n",
        "    correct /= size\n",
        "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    #val_loss.append(test_loss)\n",
        "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
        "    tb.add_scalar(\"Accuracy\", total_correct/ 28, epoch)#14 is length of trainset\n",
        "\n",
        "learning_rate = 0.001\n",
        "# defining the model\n",
        "model = Net2()\n",
        "# defining the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# defining the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "model.to(device)\n",
        "loss_fn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTeA2Plj_lVs"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "tb = SummaryWriter()\n",
        "\n",
        "for t in range(epochs):\n",
        "    loss_temp=[]\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, total_loss, t)\n",
        "    val_loop(val_dataloader, model, loss_fn, total_correct, t)\n",
        "    #train_loss.append(loss_temp.pop())\n",
        "    #print(train_loss, val_loss)\n",
        "    # plotting the training and validation loss\n",
        "    # plt.plot(train_loss, label='Training loss')\n",
        "    # plt.plot(val_loss, label='Validation loss')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    \n",
        "    tb.add_histogram(\"conv3d1.bias\", model.conv3d1.bias, t)\n",
        "    tb.add_histogram(\"conv3d1.weight\", model.conv3d1.weight, t)\n",
        "    tb.add_histogram(\"conv3d2.bias\", model.conv3d2.bias, t)\n",
        "    tb.add_histogram(\"conv3d2.weight\", model.conv3d2.weight, t)\n",
        "    tb.add_histogram(\"conv3d3.bias\", model.conv3d2.bias, t)\n",
        "    tb.add_histogram(\"conv3d3.weight\", model.conv3d2.weight, t)\n",
        "    tb.add_histogram(\"conv3d4.bias\", model.conv3d2.bias, t)\n",
        "    tb.add_histogram(\"conv3d4.weight\", model.conv3d2.weight, t)\n",
        "    tb.add_histogram(\"conv3d5.bias\", model.conv3d2.bias, t)\n",
        "    tb.add_histogram(\"conv3d5.weight\", model.conv3d2.weight, t)\n",
        "    tb.add_histogram(\"out.bias\", model.out.bias, t)\n",
        "    tb.add_histogram(\"out.weight\", model.out.weight, t)\n",
        "    #tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
        "\n",
        "\n",
        "tb.close()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bCEpzL1_lVs"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,264,264,264))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "  \n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    val_loss.append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux998Arm_lVt"
      },
      "outputs": [],
      "source": [
        "test_loop(test_dataloader, model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epjgOoaB_lVu"
      },
      "outputs": [],
      "source": [
        "tb = SummaryWriter()\n",
        "model = Net()\n",
        "images, labels = next(iter(train_dataloader))\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "tb.add_image(\"images\", grid)\n",
        "tb.add_graph(model, images)\n",
        "tb.close()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}