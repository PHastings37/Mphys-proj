{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install SimpleITK\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRGP0dFs_3iR",
        "outputId": "86d690c5-5099-4a10-eb41-cb03513b0590"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 16 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "77NOow0zA89U",
        "outputId": "876d42c0-f864-42da-cc09-20ac6da7a2f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.42.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5BF5Z3hz_lVg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import os\n",
        "from torchvision.io import read_image\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch import reshape\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Conv3d\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiD5Uq9UAQXb",
        "outputId": "ef07f9ba-b088-4d3d-8c9b-055a1573a659"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/Mphys project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN70ec46Aces",
        "outputId": "33741aa1-b6e0-4ab1-ba86-c9eab51d0de1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Mphys project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tb = SummaryWriter()"
      ],
      "metadata": {
        "id": "KVMP754lBJjx"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir = content/logsdir"
      ],
      "metadata": {
        "id": "mKanWrp_BRWB",
        "outputId": "2deda53a-ede9-4c0e-e1b0-aae98d02ad08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
            "                   [--host ADDR] [--bind_all] [--port PORT]\n",
            "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
            "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
            "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
            "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
            "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
            "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
            "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
            "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
            "                   [--reload_multifile BOOL]\n",
            "                   [--reload_multifile_inactive_secs SECONDS]\n",
            "                   [--generic_data TYPE]\n",
            "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
            "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
            "                   [--whatif-data-dir PATH]\n",
            "                   {serve,dev} ...\n",
            "tensorboard: error: invalid choice: 'content/logsdir' (choose from 'serve', 'dev')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "C6wIv-US_lVm"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "transform = ToTensor()\n",
        "croppath = \"cropped niftys short\"\n",
        "\n",
        "class Normalize():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  # def __call__(self, sample):\n",
        "  #   inputs, targets = sample\n",
        "  #   inputs = transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "  #   return inputs, targets\n",
        "  def __call__(self,vol):\n",
        "    print(\"vol\")\n",
        "    vol =(vol-vol.mean())/vol.std()\n",
        "    return vol\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [Normalize() ] #added at 11:00pm 13/12/2021 to normalize the inputs. THIS NORMALIZES to mean = 0 and std = -1(from Rory)\n",
        "# )\n",
        "\n",
        "class CustomImageDataset():\n",
        "    def __init__(self, croppath, transform=transform, target_transfrom=None):\n",
        "        #self.img_labels = pd.read_csv(\"/mnt/c/Users/Patrick/Documents/NSCLC Radiomics Lung1.clinical-version3-Oct 2019(1).csv\")\n",
        "        self.img_labels = pd.read_csv(\"cancerdata.csv\")\n",
        "        self.img_dir = croppath\n",
        "        self.transform=transform\n",
        "        self.target_transform=target_transfrom\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__ (self, idx):\n",
        "        img_path = os.path.join(self.img_dir, f\"{self.img_labels.iloc[idx, 0]}-GTV-1.nii\")\n",
        "        image = sitk.ReadImage(img_path)\n",
        "        array = sitk.GetArrayFromImage(image)\n",
        "        tensor = torch.from_numpy(array)\n",
        "        time_to_death = self.img_labels.iloc[idx,8]\n",
        "        dead_status = self.img_labels.iloc[idx,9]\n",
        "        # if self.transform :\n",
        "        #   image = self.transform(image)\n",
        "          \n",
        "        if time_to_death < 1.5*365 and dead_status == 1:\n",
        "            label=1\n",
        "        else:\n",
        "            label=0\n",
        "        \n",
        "        \n",
        "        \n",
        "        return(array, label)\n",
        "dataset = CustomImageDataset(croppath, ToTensor(), None)\n",
        "#print(len(dataset))\n",
        "\n",
        "trainset, valset, testset = torch.utils.data.random_split(dataset, [24,8,8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "Lhim6vom_lVn"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(testset, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(valset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Bfjfny_lVo",
        "outputId": "a1e90170-49f8-4e84-a79f-cd971399ce4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg5oJWjl_lVp"
      },
      "outputs": [],
      "source": [
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "  \n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv3d(1, 4, 3, 1, 1),\n",
        "            nn.BatchNorm3d(4),#normalises batch\n",
        "            ReLU(inplace=True),#applies a ReLu to the neurons\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),#finds max pool of feature map\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
        "            nn.BatchNorm3d(4),\n",
        "            ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(2048, 2)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)#calls the constructor to execute the convolutions, passes the tensor x and gets the \n",
        "        #result of the convolution passed back.\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x\n",
        "\n",
        "model = Net().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B0nQHCZBCKa",
        "outputId": "5e900723-17cb-4f73-ddc4-d8a056255d00"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [4, 4, 264, 264, 264]             112\n",
            "       BatchNorm3d-2      [4, 4, 264, 264, 264]               8\n",
            "              ReLU-3      [4, 4, 264, 264, 264]               0\n",
            "         MaxPool3d-4      [4, 4, 132, 132, 132]               0\n",
            "            Conv3d-5      [4, 4, 132, 132, 132]             436\n",
            "       BatchNorm3d-6      [4, 4, 132, 132, 132]               8\n",
            "              ReLU-7      [4, 4, 132, 132, 132]               0\n",
            "         MaxPool3d-8         [4, 4, 66, 66, 66]               0\n",
            "            Conv3d-9         [4, 4, 66, 66, 66]             436\n",
            "      BatchNorm3d-10         [4, 4, 66, 66, 66]               8\n",
            "             ReLU-11         [4, 4, 66, 66, 66]               0\n",
            "        MaxPool3d-12         [4, 4, 33, 33, 33]               0\n",
            "           Conv3d-13         [4, 4, 33, 33, 33]             436\n",
            "      BatchNorm3d-14         [4, 4, 33, 33, 33]               8\n",
            "             ReLU-15         [4, 4, 33, 33, 33]               0\n",
            "        MaxPool3d-16         [4, 4, 16, 16, 16]               0\n",
            "           Conv3d-17         [4, 4, 16, 16, 16]             436\n",
            "      BatchNorm3d-18         [4, 4, 16, 16, 16]               8\n",
            "             ReLU-19         [4, 4, 16, 16, 16]               0\n",
            "        MaxPool3d-20            [4, 4, 8, 8, 8]               0\n",
            "           Linear-21                     [4, 2]           4,098\n",
            "================================================================\n",
            "Total params: 5,994\n",
            "Trainable params: 5,994\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 8021.21\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 8301.99\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "nr5x0eFo_lVq"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class Net2(Module): \n",
        "  def __init__(self):\n",
        "    super(Net2, self).__init__()\n",
        "    self.conv3d1 = Conv3d(1, 4, 3, 2)\n",
        "    self.conv3d2 = Conv3d(4, 16, 3, 2)\n",
        "    self.conv3d3 = Conv3d(16, 64, 2, 2)\n",
        "    self.conv3d4 = Conv3d(64, 256, 2, 2)\n",
        "    self.Lin1 = Linear(256, 64)\n",
        "    self.out = Linear(64,2)\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv3d1(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    x = F.relu(self.conv3d2(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    x = F.relu(self.conv3d3(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    x = F.relu(self.conv3d4(x))\n",
        "    x = F.max_pool3d(x, 2, 2)\n",
        "    # x = F.relu(self.conv3d5(x))\n",
        "    # x = F.max_pool3d(x, 2, 2)\n",
        "    x = x.view(-1, 256)\n",
        "    x = F.relu(self.Lin1(x))\n",
        "    #x = torch.flatten(x, start_dim = 1)\n",
        "    x = self.out(x)\n",
        "    return(x)\n",
        "model = Net2().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUhrhM8qBPpy",
        "outputId": "102b0000-fbe9-482e-b272-e9d09a657246"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [4, 4, 131, 131, 131]             112\n",
            "            Conv3d-2        [4, 16, 32, 32, 32]           1,744\n",
            "            Conv3d-3           [4, 64, 8, 8, 8]           8,256\n",
            "            Conv3d-4          [4, 256, 2, 2, 2]         131,328\n",
            "            Linear-5                    [4, 64]          16,448\n",
            "            Linear-6                     [4, 2]             130\n",
            "================================================================\n",
            "Total params: 158,018\n",
            "Trainable params: 158,018\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 291.49\n",
            "Params size (MB): 0.60\n",
            "Estimated Total Size (MB): 572.85\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fE0hMfu_lVr",
        "outputId": "936bc148-754c-428d-bc86-fb0bd5379eea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, total_loss, epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        \n",
        "             \n",
        "\n",
        "        # Compute prediction and loss\n",
        "        X = reshape(X, (X.shape[0],1,264,264,264))\n",
        "        X = X.float()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        total_loss += loss\n",
        "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn, total_correct, epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    val_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,264,264,264))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            val_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            total_correct += correct\n",
        "    val_loss /= num_batches\n",
        "  \n",
        "    correct /= size\n",
        "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")\n",
        "    #val_loss.append(test_loss)\n",
        "    # tb.add_scalar(\"Correct\", total_correct, epoch)\n",
        "    tb.add_scalar(\"Accuracy\", total_correct/ 28, epoch)#14 is length of trainset\n",
        "    tb.add_scalar(\"val loss\", val_loss, epoch)\n",
        "\n",
        "learning_rate = 0.001\n",
        "# defining the model\n",
        "model = Net2()\n",
        "# defining the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# defining the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "model.to(device)\n",
        "loss_fn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "WTeA2Plj_lVs",
        "outputId": "4e3cf3b3-85f3-47c3-d461-3f046c9022b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-652b7a247721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#train_loss.append(loss_temp.pop())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-130-6e1ad48c19d4>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, total_loss, epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_strict_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mrecord\u001b[0m \u001b[0myour\u001b[0m \u001b[0mmutable\u001b[0m \u001b[0mcontainer\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_strict_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mselect_model_mode_for_export\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mis_originally_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'Net2' has no attribute 'training'"
          ]
        }
      ],
      "source": [
        "epochs = 1\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "\n",
        "for t in range(epochs):\n",
        "    loss_temp=[]\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, total_loss, t)\n",
        "    val_loop(val_dataloader, model, loss_fn, total_correct, t)\n",
        "    #train_loss.append(loss_temp.pop())\n",
        "    #print(train_loss, val_loss)\n",
        "    # plotting the training and validation loss\n",
        "    # plt.plot(train_loss, label='Training loss')\n",
        "    # plt.plot(val_loss, label='Validation loss')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    tb.add_histogram(\"conv3d1.bias\", model.conv3d1.bias, t)\n",
        "    tb.add_histogram(\"conv3d1.weight\", model.conv3d1.weight, t)\n",
        "    tb.add_histogram(\"conv3d2.bias\", model.conv3d2.bias, t)\n",
        "    tb.add_histogram(\"conv3d2.weight\", model.conv3d2.weight, t)\n",
        "    tb.add_histogram(\"conv3d3.bias\", model.conv3d3.bias, t)\n",
        "    tb.add_histogram(\"conv3d3.weight\", model.conv3d3.weight, t)\n",
        "    tb.add_histogram(\"conv3d4.bias\", model.conv3d4.bias, t)\n",
        "    tb.add_histogram(\"conv3d4.weight\", model.conv3d4.weight, t)\n",
        "    tb.add_histogram(\"Lin1.bias\", model.Lin1.bias, t)\n",
        "    tb.add_histogram(\"Lin1.weight\", model.Lin1.weight, t)\n",
        "    tb.add_histogram(\"out.bias\", model.out.bias, t)\n",
        "    tb.add_histogram(\"out.weight\", model.out.weight, t)\n",
        "    #tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
        "\n",
        "\n",
        "tb.close()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bCEpzL1_lVs"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,264,264,264))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "  \n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    val_loss.append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux998Arm_lVt"
      },
      "outputs": [],
      "source": [
        "test_loop(test_dataloader, model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epjgOoaB_lVu"
      },
      "outputs": [],
      "source": [
        "tb = SummaryWriter()\n",
        "model = Net()\n",
        "images, labels = next(iter(train_dataloader))\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "tb.add_image(\"images\", grid)\n",
        "tb.add_graph(model, images)\n",
        "tb.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = Net2()\n",
        "images, labels = next(iter(train_dataloader))\n",
        "images = reshape(images, (images.shape[0],1,264,264,264))\n",
        "images = images.float()\n",
        "\n",
        "tb.add_graph(network, images)\n",
        "tb.close()"
      ],
      "metadata": {
        "id": "6T3bcb2cDV46"
      },
      "execution_count": 148,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}