{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch import reshape\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Conv3d\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "transform = ToTensor()\n",
    "croppath = \"cropped niftys short\"\n",
    "\n",
    "class CustomImageDataset():\n",
    "    def __init__(self, croppath, transform=None, target_transfrom=None):\n",
    "        #self.img_labels = pd.read_csv(\"/mnt/c/Users/Patrick/Documents/NSCLC Radiomics Lung1.clinical-version3-Oct 2019(1).csv\")\n",
    "        #needs new path\n",
    "        self.img_labels = pd.read_csv(\"cancerdata.csv\")\n",
    "        #print(self.img_labels)\n",
    "        self.img_dir = croppath\n",
    "        self.transform=transform\n",
    "        #print(self.transform)\n",
    "        self.target_transform=target_transfrom\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__ (self, idx):\n",
    "        img_path = os.path.join(self.img_dir, f\"{self.img_labels.iloc[idx, 0]}-GTV-1.nii\")\n",
    "        image = sitk.ReadImage(img_path)\n",
    "        array = sitk.GetArrayFromImage(image)\n",
    "        #tensor = torch.from_numpy(array)\n",
    "        time_to_death = self.img_labels.iloc[idx,8]\n",
    "        dead_status = self.img_labels.iloc[idx,9]\n",
    "        if time_to_death < 1.5*365 and dead_status == 1:\n",
    "            label=1\n",
    "        else:\n",
    "            label=0\n",
    "        \n",
    "        return(array, label)\n",
    "dataset = CustomImageDataset(croppath, ToTensor(), None)\n",
    "#print(len(dataset))\n",
    "\n",
    "trainset, valset, testset = torch.utils.data.random_split(dataset, [24,8,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "train_features = next(iter(train_dataloader))\n",
    "test_dataloader = DataLoader(testset, batch_size=4, shuffle=True)\n",
    "test_features = next(iter(train_dataloader))\n",
    "val_dataloader = DataLoader(valset, batch_size=4, shuffle=True)\n",
    "val_features = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "  \n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv3d(1, 4, 3, 1, 1),\n",
    "            nn.BatchNorm3d(4),#normalises batch\n",
    "            ReLU(inplace=True),#applies a ReLu to the neurons\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),#finds max pool of feature map\n",
    "\n",
    "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
    "            nn.BatchNorm3d(4),\n",
    "            ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "\n",
    "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
    "            nn.BatchNorm3d(4),\n",
    "            ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "\n",
    "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
    "            nn.BatchNorm3d(4),\n",
    "            ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "\n",
    "            Conv3d(4, 4, 3, 1, 1),#64 neurons per layer\n",
    "            nn.BatchNorm3d(4),\n",
    "            ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(2048, 2)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)#calls the constructor to execute the convolutions, passes the tensor x and gets the \n",
    "        #result of the convolution passed back.\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Net2(Module): \n",
    "  def __init__(self):\n",
    "    super(Net2, self).__init__()\n",
    "    self.conv3d1 = Conv3d(1, 4, 3, 1, 1)\n",
    "    self.conv3d2 = Conv3d(4, 4, 3, 1, 1)\n",
    "    self.conv3d3 = Conv3d(4, 4, 3, 1, 1)\n",
    "    self.conv3d4 = Conv3d(4, 4, 3, 1, 1)\n",
    "    self.conv3d5 = Conv3d(4, 4, 3, 1, 1)\n",
    "    self.out = Linear(2048,2)\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3d1(x))\n",
    "    x = F.max_pool3d(x, 2, 2)\n",
    "    x = F.relu(self.conv3d2(x))\n",
    "    x = F.max_pool3d(x, 2, 2)\n",
    "    x = F.relu(self.conv3d3(x))\n",
    "    x = F.max_pool3d(x, 2, 2)\n",
    "    x = F.relu(self.conv3d4(x))\n",
    "    x = F.max_pool3d(x, 2, 2)\n",
    "    x = F.relu(self.conv3d5(x))\n",
    "    x = F.max_pool3d(x, 2, 2)\n",
    "    x = torch.flatten(x, start_dim = 1)\n",
    "    x = self.out(x)\n",
    "    return(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, total_loss, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = reshape(X, (X.shape[0],1,264,264,264))\n",
    "        X = X.float()\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        total_loss += loss\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "\n",
    "def val_loop(dataloader, model, loss_fn, total_correct, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = reshape(X, (X.shape[0],1,264,264,264))\n",
    "            X = X.float()\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            total_correct += correct\n",
    "    test_loss /= num_batches\n",
    "  \n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    #val_loss.append(test_loss)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct/ 28, epoch)#14 is length of trainset\n",
    "\n",
    "learning_rate = 0.001\n",
    "# defining the model\n",
    "model = Net2()\n",
    "# defining the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# defining the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "model.to(device)\n",
    "loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "tb = SummaryWriter()\n",
    "\n",
    "for t in range(epochs):\n",
    "    loss_temp=[]\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, total_loss, t)\n",
    "    val_loop(val_dataloader, model, loss_fn, total_correct, t)\n",
    "    #train_loss.append(loss_temp.pop())\n",
    "    #print(train_loss, val_loss)\n",
    "    # plotting the training and validation loss\n",
    "    # plt.plot(train_loss, label='Training loss')\n",
    "    # plt.plot(val_loss, label='Validation loss')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    \n",
    "    tb.add_histogram(\"conv3d1.bias\", model.conv3d1.bias, t)\n",
    "    tb.add_histogram(\"conv3d1.weight\", model.conv3d1.weight, t)\n",
    "    tb.add_histogram(\"conv3d2.bias\", model.conv3d2.bias, t)\n",
    "    tb.add_histogram(\"conv3d2.weight\", model.conv3d2.weight, t)\n",
    "    tb.add_histogram(\"conv3d3.bias\", model.conv3d2.bias, t)\n",
    "    tb.add_histogram(\"conv3d3.weight\", model.conv3d2.weight, t)\n",
    "    tb.add_histogram(\"conv3d4.bias\", model.conv3d2.bias, t)\n",
    "    tb.add_histogram(\"conv3d4.weight\", model.conv3d2.weight, t)\n",
    "    tb.add_histogram(\"conv3d5.bias\", model.conv3d2.bias, t)\n",
    "    tb.add_histogram(\"conv3d5.weight\", model.conv3d2.weight, t)\n",
    "    tb.add_histogram(\"out.bias\", model.out.bias, t)\n",
    "    tb.add_histogram(\"out.weight\", model.out.weight, t)\n",
    "    #tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
    "\n",
    "\n",
    "tb.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = reshape(X, (X.shape[0],1,264,264,264))\n",
    "            X = X.float()\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "  \n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    val_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "model = Net()\n",
    "images, labels = next(iter(train_dataloader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, images)\n",
    "tb.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
